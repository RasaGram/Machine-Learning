{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8721817,"sourceType":"datasetVersion","datasetId":5233744}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nimport os\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ntrain_data_dir = '/kaggle/input/indonesian-food-mendeley/train'\ntest_data_dir = '/kaggle/input/indonesian-food-mendeley/test'\n\nimg_height, img_width = 224, 224\nbatch_size = 32\n\ntrain_datagen = ImageDataGenerator(\n    rescale=1. / 255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    validation_split = 0.3\n)\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_data_dir,\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset = 'training',\n    shuffle=True \n)\n\nvalidation_generator = train_datagen.flow_from_directory(\n    train_data_dir,\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset = 'validation'\n)\n\ntest_datagen = ImageDataGenerator(rescale = 1. / 255. )\ntest_generator = train_datagen.flow_from_directory(\n    test_data_dir,\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='categorical',\n)\n\ndef plot_images_from_generator(generator, num_images):\n    images, labels = next(generator)\n    \n    class_indices = {v: k for k, v in generator.class_indices.items()}\n    \n    plt.figure(figsize=(15, 10))\n    for i in range(num_images):\n        plt.subplot(4, 4, i + 1)\n        plt.imshow(images[i])\n        plt.title(class_indices[np.argmax(labels[i])])\n        plt.axis('off')\n    plt.show()\n\nplot_images_from_generator(train_generator, 16)\nplot_images_from_generator(validation_generator, 16)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-18T19:06:39.657966Z","iopub.execute_input":"2024-06-18T19:06:39.65885Z","iopub.status.idle":"2024-06-18T19:06:44.01869Z","shell.execute_reply.started":"2024-06-18T19:06:39.658818Z","shell.execute_reply":"2024-06-18T19:06:44.017825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, Flatten, Dense, Dropout, BatchNormalization\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.applications import MobileNetV2\nimport os\n\nimg_height, img_width = 224, 224\nbatch_size = 32\n\nbase_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n\nfor layer in base_model.layers:\n    layer.trainable = False\n\nmodel = Sequential()\nmodel.add(base_model)\nmodel.add(Dropout(0.4))\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation='softmax'))\n\nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate = 0.001),\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\nmodel.summary()\n\n\nearly_stopping = EarlyStopping(monitor='val_loss', patience=25, verbose=2)\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6, verbose=2)\n\nhistory = model.fit(\n    train_generator,\n    validation_data=validation_generator,\n    epochs=100,\n    callbacks=[early_stopping, reduce_lr]\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-18T19:06:44.02047Z","iopub.execute_input":"2024-06-18T19:06:44.020812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.figure(figsize=(12, 6))\nplt.subplot(1, 2, 1)\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc='upper left')\nplt.grid(True)\n\nplt.subplot(1, 2, 2)\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc='upper right')\nplt.grid(True)\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_names = list(validation_generator.class_indices.keys())\nclass_names","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import itertools\nfrom sklearn.metrics import confusion_matrix, classification_report\n\nclass_names = list(validation_generator.class_indices.keys())\nnum_classes = len(class_names)\n\nloss, accuracy = model.evaluate(validation_generator)\nprint(f'Validation Accuracy: {accuracy:.4f}')\nprint(f'Validation Loss: {loss:.4f}')\n\ntest_loss, test_accuracy = model.evaluate(test_generator)\nprint(f'Test Accuracy: {test_accuracy:.4f}')\nprint(f'Test Loss: {test_loss:.4f}')\n\ny_pred_prob = model.predict(validation_generator)\ny_pred = np.argmax(y_pred_prob, axis=1)\ntrue_labels = validation_generator.classes\ncm = confusion_matrix(true_labels, y_pred)\n\nplt.figure(figsize=(8, 6))\nplt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\nplt.title('Confusion Matrix - Validation Set')\nplt.colorbar()\ntick_marks = np.arange(len(class_names))\nplt.xticks(tick_marks, class_names, rotation=45)\nplt.yticks(tick_marks, class_names)\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\n\nthresh = cm.max() / 2.\nfor i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n    plt.text(j, i, format(cm[i, j], 'd'),\n             horizontalalignment=\"center\",\n             color=\"white\" if cm[i, j] > thresh else \"black\")\n\nplt.tight_layout()\nplt.show()\n\nprint('Classification Report - Validation Set:')\nprint(classification_report(true_labels, y_pred, target_names=class_names))\n\nplt.figure(figsize=(12, 6))\n\nplt.subplot(1, 2, 1)\nplt.plot(history.history['accuracy'], label='Training Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.title('Training and Validation Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(history.history['loss'], label='Training Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.title('Training and Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n\nlabels = ['Validation', 'Test']\naccuracies = [accuracy, test_accuracy]\n\nplt.bar(labels, accuracies, color=['blue', 'green'])\nplt.ylabel('Accuracy')\nplt.title('Validation vs Test Accuracy')\nplt.ylim(0, 1)\nplt.show()\n\nnum_images_to_plot = 5\nindices = np.random.choice(len(validation_generator.filenames), size=num_images_to_plot, replace=False)\n\nplt.figure(figsize=(15, 10))\nfor i, idx in enumerate(indices):\n    filename = validation_generator.filenames[idx]\n    true_label = class_names[true_labels[idx]]\n    predicted_label = class_names[y_pred[idx]]\n    \n    img = plt.imread(os.path.join(validation_generator.directory, filename))\n    plt.subplot(1, num_images_to_plot, i + 1)\n    plt.imshow(img)\n    plt.title(f'True: {true_label}\\nPredicted: {predicted_label}')\n    plt.axis('off')\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('model.h5', save_format='tf')\n\nmodel_json = model.to_json()\nwith open('model.json', 'w') as json_file:\n    json_file.write(model_json)\n\nmodel.save_weights('model_weights.weights.h5')\n\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\ntflite_model = converter.convert()\n\nwith open('model.tflite', 'wb') as tflite_file:\n    tflite_file.write(tflite_model)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}